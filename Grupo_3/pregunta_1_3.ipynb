{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grupo 3 del proyecto de data mining - Analisis de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Authors : H. Kanza, N.Matte, J. Escrihuela, A. Ortiz, ...***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Import data from the website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I download the HTML page where I can find the URLs of every monthly file I want to analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at data/webpage_omie.html\n"
     ]
    }
   ],
   "source": [
    "# URL of the file I want to download\n",
    "url_page = \"https://www.omie.es/en/file-access-list?parents%5B0%5D=/&parents%5B1%5D=Day-ahead%20Market&parents%5B2%5D=3.%20Curves&dir=Monthly%20files%20with%20aggregate%20supply%20and%20demand%20curves%20of%20Day-ahead%20market%20including%20bid%20units&realdir=curva_pbc_uof\"\n",
    "\n",
    "# Path where I want to save the file\n",
    "path = \"data/webpage_omie.html\"\n",
    "\n",
    "# GET request to try to access URL data\n",
    "response = requests.get(url_page)\n",
    "\n",
    "# I make sure the request succeeded\n",
    "if response.status_code == 200:\n",
    "    # ... so I write the data in a local file, in the specified path\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"File saved at {path}\")\n",
    "else:\n",
    "    print(f\"Request error code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with the HTML, I need to extract the list containing the URLs of all curves files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 occurences found on the webpage.\n"
     ]
    }
   ],
   "source": [
    "# I read the HTML file\n",
    "with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "    # Pattern with characters before and after\n",
    "    pattern = r\".*curva_pbc_uof_*.\"\n",
    "\n",
    "    # Find occurrences that match the pattern\n",
    "    matches = re.findall(pattern, html_content)\n",
    "\n",
    "    if matches:\n",
    "        print(len(matches), \"occurences found on the webpage.\")\n",
    "    else:\n",
    "        print(\"No occurence found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descarga completa: data/curva_pibc_uof_202402.zip\n"
     ]
    }
   ],
   "source": [
    "# URL de la página con la lista de archivos\n",
    "url_page = \"https://www.omie.es/en/file-access-list?parents%5B0%5D=/&parents%5B1%5D=Intraday%20Auction%20Market&parents%5B2%5D=3.%20Curves&dir=Monthly%20files%20with%20aggregate%20supply%20and%20demnand%20curves%20of%20intraday%20auction%20market%20including%20bid%20units&realdir=curva_pibc_uof\"\n",
    "\n",
    "# Hacer una solicitud GET para obtener el contenido de la página\n",
    "response = requests.get(url_page)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parsear el contenido HTML\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Buscar todos los enlaces en la página que coincidan con el patrón de nombre del archivo\n",
    "    links = soup.find_all('a', href=True)\n",
    "    file_names = [re.search(r'curva_pibc_uof_\\d{6}.zip', link['href']).group(0) for link in links if re.search(r'curva_pibc_uof_\\d{6}.zip', link['href'])]\n",
    "\n",
    "    if file_names:\n",
    "        # Ordenar los nombres de archivos por fecha de más reciente a más antiguo\n",
    "        file_names.sort(reverse=True)\n",
    "\n",
    "        # Obtener el nombre del archivo más reciente\n",
    "        latest_file_name = file_names[0]\n",
    "\n",
    "        # Construir la URL completa del archivo más reciente encontrado\n",
    "        latest_file_url = f\"https://www.omie.es/en/file-download?parents%5B0%5D=curva_pibc_uof&filename={latest_file_name}\"\n",
    "        # Nombre del archivo a guardar en el disco\n",
    "        file_name = f\"data/{latest_file_name}\"\n",
    "\n",
    "        # Hacer una solicitud GET para descargar el archivo ZIP\n",
    "        response = requests.get(latest_file_url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # Guardar el archivo ZIP en la ruta especificada\n",
    "            os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "            with open(file_name, \"wb\") as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"Descarga completa: {file_name}\")\n",
    "        else:\n",
    "            print(f\"Error al descargar el archivo: {response.status_code}\")\n",
    "    else:\n",
    "        print(\"No se encontraron archivos que coincidan con el patrón especificado.\")\n",
    "else:\n",
    "    print(f\"Error en la solicitud a la página: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorio_destino = 'descomprimido/'\n",
    "# Extraer el archivo zip\n",
    "with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
    "    zip_ref.extractall(directorio_destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la lista de archivos descomprimidos\n",
    "archivos_descomprimidos = os.listdir(directorio_destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambiar el nombre de los archivos .1 a .csv\n",
    "for archivo in archivos_descomprimidos:\n",
    "    if archivo.endswith('.1'):\n",
    "        # Construir las rutas de origen y destino\n",
    "        ruta_origen = os.path.join(directorio_destino, archivo)\n",
    "        ruta_destino = os.path.join(directorio_destino, archivo[:-2] + '.csv')\n",
    "        # Renombrar el archivo\n",
    "        os.rename(ruta_origen, ruta_destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la lista de archivos CSV en el directorio\n",
    "archivos_descomprimidos = [f for f in os.listdir(directorio_destino) if f.endswith('.csv')]\n",
    "\n",
    "# Inicializar un DataFrame vacío para almacenar los datos combinados\n",
    "data_frame_combinado = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre los archivos CSV y leerlos en el DataFrame\n",
    "for archivo in archivos_descomprimidos:\n",
    "    ruta_archivo = os.path.join(directorio_destino, archivo)\n",
    "    # Leer el archivo saltando las dos primeras filas y usando la tercera fila como encabezado\n",
    "    datos_archivo = pd.read_csv(ruta_archivo, skiprows=2,delimiter=';')\n",
    "    # Concatenar los datos al DataFrame combinado\n",
    "    data_frame_combinado = pd.concat([data_frame_combinado, datos_archivo], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hora</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Pais</th>\n",
       "      <th>Unidad</th>\n",
       "      <th>Tipo Oferta</th>\n",
       "      <th>Energ�a Compra/Venta</th>\n",
       "      <th>Precio Compra/Venta</th>\n",
       "      <th>Ofertada (O)/Casada (C)</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>01/02/2024</td>\n",
       "      <td>MI</td>\n",
       "      <td>WMVD101</td>\n",
       "      <td>C</td>\n",
       "      <td>0,2</td>\n",
       "      <td>1.002,00</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>01/02/2024</td>\n",
       "      <td>MI</td>\n",
       "      <td>WMVD147</td>\n",
       "      <td>C</td>\n",
       "      <td>0,1</td>\n",
       "      <td>1.002,00</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>01/02/2024</td>\n",
       "      <td>MI</td>\n",
       "      <td>IBEVD15</td>\n",
       "      <td>C</td>\n",
       "      <td>2,0</td>\n",
       "      <td>801,00</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>01/02/2024</td>\n",
       "      <td>MI</td>\n",
       "      <td>IBEVD14</td>\n",
       "      <td>C</td>\n",
       "      <td>2,0</td>\n",
       "      <td>801,00</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>01/02/2024</td>\n",
       "      <td>MI</td>\n",
       "      <td>NXVD219</td>\n",
       "      <td>C</td>\n",
       "      <td>49,5</td>\n",
       "      <td>700,00</td>\n",
       "      <td>O</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hora       Fecha Pais   Unidad Tipo Oferta Energ�a Compra/Venta  \\\n",
       "0   1.0  01/02/2024   MI  WMVD101           C                  0,2   \n",
       "1   1.0  01/02/2024   MI  WMVD147           C                  0,1   \n",
       "2   1.0  01/02/2024   MI  IBEVD15           C                  2,0   \n",
       "3   1.0  01/02/2024   MI  IBEVD14           C                  2,0   \n",
       "4   1.0  01/02/2024   MI  NXVD219           C                 49,5   \n",
       "\n",
       "  Precio Compra/Venta Ofertada (O)/Casada (C)  Unnamed: 8  \n",
       "0            1.002,00                       O         NaN  \n",
       "1            1.002,00                       O         NaN  \n",
       "2              801,00                       O         NaN  \n",
       "3              801,00                       O         NaN  \n",
       "4              700,00                       O         NaN  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame_combinado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (JAIME MARTIN) In this Section, We are going to clean and prepare Data obtained from various\n",
    "# sources related to the OMIE SPOT Electricity\n",
    "#1 Handly Missing Values\n",
    "#2 Removing Outliers\n",
    "#3 Data Normalization \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
